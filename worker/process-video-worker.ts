import 'dotenv/config'
import fs from 'fs'
import { execSync } from 'child_process'
import path from 'path'
import { createClient } from '@supabase/supabase-js'
import { Redis } from '@upstash/redis'
import { Readable } from 'stream'

const redis = new Redis({
    url: process.env.UPSTASH_REDIS_REST_URL!,
    token: process.env.UPSTASH_REDIS_REST_TOKEN!,
})

const supabase = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
)

const TMP = '/tmp'
if (!fs.existsSync(TMP)) {
    console.error('‚ùå Th∆∞ m·ª•c /tmp kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng th·ªÉ ghi!')
    process.exit(1)
}

async function download(url: string, dest: string) {
    const res = await fetch(url)
    if (!res.ok || !res.body) throw new Error(`‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c: ${url}`)

    const fileStream = fs.createWriteStream(dest)
    const nodeStream = Readable.from(res.body as any)

    await new Promise<void>((resolve, reject) => {
        nodeStream.pipe(fileStream)
        nodeStream.on('error', reject)
        fileStream.on('finish', resolve)
    })
}

const checkFileSize = (filePath: string) => {
    try {
        const stats = fs.statSync(filePath)
        return stats.size > 0
    } catch {
        return false
    }
}

const extractPath = (url: string) => {
    try {
        const parts = url.split(`/storage/v1/object/public/${process.env.SUPABASE_STORAGE_BUCKET}/`)
        if (parts.length === 2) {
            return parts[1]
        }
        return ''
    } catch {
        return ''
    }
}

async function processJob(job: { jobId: string; videoUrl: string; audioUrl: string; outputName: string }) {
    console.log('üìå Debug: job nh·∫≠n t·ª´ Redis =', job)

    if (!job.jobId || !job.videoUrl || !job.audioUrl || !job.outputName) {
        console.error('‚ùå Thi·∫øu tr∆∞·ªùng b·∫Øt bu·ªôc trong job:', job)
        process.exit(1)
    }

    const inputVideo = path.join(TMP, 'input.mp4')
    const inputAudio = path.join(TMP, 'input.mp3')
    const cleanVideo = path.join(TMP, 'clean.mp4')
    const outputFile = path.join(TMP, job.outputName)

    try {
        console.log('üì• ƒêang t·∫£i video + audio t·ª´ Supabase...')
        await download(job.videoUrl, inputVideo)
        await download(job.audioUrl, inputAudio)

        if (!fs.existsSync(inputVideo) || !fs.existsSync(inputAudio)) {
            throw new Error('‚ùå File t·∫£i v·ªÅ kh√¥ng t·ªìn t·∫°i!')
        }
        if (!checkFileSize(inputVideo) || !checkFileSize(inputAudio)) {
            throw new Error('‚ùå File t·∫£i v·ªÅ c√≥ dung l∆∞·ª£ng 0, kh√¥ng h·ª£p l·ªá!')
        }

        console.log('‚úÇÔ∏è ƒêang t√°ch audio kh·ªèi video...')
        execSync(`ffmpeg -i ${inputVideo} -an -c:v copy ${cleanVideo} -y`)

        console.log('üéß ƒêang gh√©p audio g·ªëc v√†o video s·∫°ch...')
        execSync(`ffmpeg -i ${cleanVideo} -i ${inputAudio} -c:v copy -c:a aac -shortest ${outputFile} -y`)

        console.log('üìå Upload l√™n Supabase...')
        const { error } = await supabase.storage
            .from(process.env.SUPABASE_STORAGE_BUCKET!)
            .upload(`outputs/${job.outputName}`, fs.createReadStream(outputFile), {
                contentType: 'video/mp4',
                upsert: true,
            })

        if (error) {
            throw new Error('‚ùå L·ªói upload file merged: ' + error.message)
        }

        // X√≥a file t·∫°m
        for (const f of [inputVideo, inputAudio, cleanVideo, outputFile]) {
            try {
                if (fs.existsSync(f)) {
                    fs.unlinkSync(f)
                }
            } catch { }
        }

        // X√≥a file ngu·ªìn g·ªëc trong Supabase
        const videoPath = extractPath(job.videoUrl)
        const audioPath = extractPath(job.audioUrl)

        if (videoPath) {
            try {
                await supabase.storage.from(process.env.SUPABASE_STORAGE_BUCKET!).remove([videoPath])
            } catch { }
        }
        if (audioPath) {
            try {
                await supabase.storage.from(process.env.SUPABASE_STORAGE_BUCKET!).remove([audioPath])
            } catch { }
        }

        console.log(`‚úÖ Ho√†n t·∫•t job ${job.jobId}: outputs/${job.outputName}`)
    } catch (err) {
        console.error(`‚ùå L·ªói x·ª≠ l√Ω job ${job.jobId}:`, err)
        // X√≥a file t·∫°m d√π l·ªói
        for (const f of [inputVideo, inputAudio, cleanVideo, outputFile]) {
            try {
                if (fs.existsSync(f)) {
                    fs.unlinkSync(f)
                }
            } catch { }
        }
        process.exit(1)
    }
}

async function runWorker() {
    console.log('‚è≥ Worker Onlook ƒëang ch·∫°y...')

    const jobId = process.env.JOB_ID
    if (!jobId) {
        console.error('‚ùå Thi·∫øu bi·∫øn m√¥i tr∆∞·ªùng JOB_ID!')
        process.exit(1)
    }
    console.log('üü¢ Worker nh·∫≠n JOB_ID:', jobId)

    try {
        const jobJsonRaw = await redis.hget('onlook:jobs', jobId)
        if (!jobJsonRaw || typeof jobJsonRaw !== 'string') {
            console.error(`‚ùå Kh√¥ng t√¨m th·∫•y job ${jobId} trong Redis ho·∫∑c d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá!`)
            process.exit(1)
        }
        const jobJson = jobJsonRaw as string

        const job = JSON.parse(jobJson)
        await processJob(job)

        await redis.hdel('onlook:jobs', jobId)
        console.log(`‚úÖ ƒê√£ x√≥a job ${jobId} kh·ªèi Redis`)

        console.log('‚úÖ Worker ho√†n th√†nh job, tho√°t...')
        process.exit(0)
    } catch (err) {
        console.error('‚ùå L·ªói worker:', err)
        process.exit(1)
    }
}

runWorker()
